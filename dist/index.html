
  <!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
      :root {
        --bg-color: #121212;
        --container-bg: #1e1e1e;
        --text-color: #e0e0e0;
        --heading-color: #ffffff;
        --subheading-color: #58a6ff;
        --link-color: #58a6ff;
        --border-color: #333333;
        --item-hover: #2a2a2a;
        --shadow: 0 4px 12px rgba(0,0,0,0.2);
        --accent-color: #58a6ff;
        --tooltip-bg: #2a2a2a;
        --tooltip-text: #e0e0e0;
        --table-header-bg: #2a2a2a;
        --table-header-text: #ffffff;
        --table-row-odd: #1e1e1e;
        --table-row-even: #252525;
      }
      
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
        line-height: 1.5;
        color: var(--text-color);
        background-color: var(--bg-color);
        margin: 0;
        padding: 0;
      }
      
      .container {
        max-width: 800px;
        margin: 0 auto;
        padding: 15px;
      }
      
      .card {
        background-color: var(--container-bg);
        border-radius: 8px;
        box-shadow: var(--shadow);
        padding: 16px;
        margin-bottom: 16px;
        transition: all 0.2s ease;
      }
      
      .card:hover {
        box-shadow: 0 6px 12px rgba(0,0,0,0.15);
      }

      .header-p {
        margin: 0.2em 0;
        font-weight: 500;
        letter-spacing: -0.02em;
        font-size: 14px;
      }

      .subreddit {
        text-align: right;
      }
      
      h2 {
        font-size: 18px;
        font-weight: 600;
        color: var(--heading-color);
        margin-top: 0;
        margin-bottom: 12px;
        padding-bottom: 6px;
        border-bottom: 2px solid var(--accent-color);
      }
      
      h3 {
        font-size: 16px;
        font-weight: 500;
        color: var(--subheading-color);
        margin-bottom: 8px;
      }
      
      a {
        color: var(--link-color);
        text-decoration: none;
        transition: color 0.2s ease;
      }
      
      a:hover {
        color: var(--accent-color);
        text-decoration: underline;
      }
      
      /* Weather Table Styles */
      .weather-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
        border-radius: 6px;
        overflow: hidden;
      }
      
      .weather-table th {
        background-color: var(--table-header-bg);
        color: var(--table-header-text);
        font-weight: 500;
        text-align: left;
        padding: 8px 12px;
        font-size: 14px;
      }
      
      .weather-table td {
        padding: 8px 12px;
        border-bottom: 1px solid var(--border-color);
        font-size: 14px;
      }
      
      .weather-table tr:nth-child(odd) {
        background-color: var(--table-row-odd);
      }
      
      .weather-table tr:nth-child(even) {
        background-color: var(--table-row-even);
      }
      
      .weather-table tr:last-child td {
        border-bottom: none;
      }
      
      .comic {
        display: flex;
        flex-direction: column;
        align-items: center;
        margin: 12px 0;
      }
      
      .comic-title {
        font-weight: 600;
        margin-bottom: 8px;
        text-align: center;
        font-size: 15px;
      }
      
      .comic img {
        max-width: 600px;
        max-height: auto;
        object-fit: contain;
        border-radius: 6px;
        margin-bottom: 6px;
        cursor: pointer;
      }
      
      .comic-number {
        font-size: 12px;
        color: var(--text-color);
        opacity: 0.7;
        margin-top: 3px;
      }
      
      .item-list {
        list-style: none;
        padding: 0;
        margin: 0;
      }
      
      .item-list li {
        padding: 8px 10px;
        border-bottom: 1px solid var(--border-color);
        position: relative;
        font-size: 14px;
      }
      
      .item-list li:last-child {
        border-bottom: none;
      }
      
      .item-list li:hover {
        background-color: var(--item-hover);
        border-radius: 4px;
      }
      
      .item-content {
        display: none;
        position: absolute;
        z-index: 10;
        background-color: var(--tooltip-bg);
        color: var(--tooltip-text);
        border-radius: 6px;
        padding: 15px;
        width: 90%;
        max-width: 100%;
        box-shadow: 0 4px 16px rgba(0,0,0,0.3);
        left: 50%;
        transform: translateX(-50%);
        bottom: 100%;
        font-size: 13px;
        line-height: 1.4;
        overflow: auto;
        max-height: 250px;
        border: 4px solid var(--border-color);
      }

      .item-content::-webkit-scrollbar {
        display: none;
      }

      .item-list li:hover .item-content {
        display: block;
      }
      
      .item-list li::before {
        content: "‚Ä¢";
        color: var(--accent-color);
        font-weight: bold;
        display: inline-block;
        width: 1em;
        margin-left: -0.5em;
      }
      
      @media (max-width: 600px) {
        .container {
          padding: 10px;
        }
        
        .card {
          padding: 12px;
          margin-bottom: 12px;
        }
        
        .item-content {
          width: 95%;
          left: 2.5%;
          transform: none;
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
  
      <div class="card">
        <h2>Huginn Daily</h2>
        <p class="header-p">Sunday, March 1, 2026</p>
        <p class="header-p">f6c8cfd6-7ea9-4ce9-858c-a791b1d182fd</p>
      </div>
  
      <div class="card">
        <h2>Weather</h2>
        <table class="weather-table">
          <tr>
            <th>Summary</th>
            <td>‚õÖÔ∏è Mostly clear until afternoon, returning in the evening.</td>
          </tr>
          <tr>
            <th>Temperature Range</th>
            <td>7¬∞C to 16¬∞C (44¬∞F to 61¬∞F)</td>
          </tr>
          <tr>
            <th>Feels Like</th>
            <td>Low: 37¬∞F | High: 61¬∞F</td>
          </tr>
          <tr>
            <th>Humidity</th>
            <td>57%</td>
          </tr>
          <tr>
            <th>Wind</th>
            <td>10 km/h (6 mph), Direction: 211¬∞</td>
          </tr>
          <tr>
            <th>Precipitation</th>
            <td>Probability: 8%, Type: No precipitation expected</td>
          </tr>
          <tr>
            <th>Sunrise / Sunset</th>
            <td>üåÖ 06:17 AM / üåá 05:43 PM</td>
          </tr>
          <tr>
            <th>Moon Phase</th>
            <td>Waxing Gibbous (43%)</td>
          </tr>
          <tr>
            <th>Cloud Cover</th>
            <td>30%</td>
          </tr>
          <tr>
            <th>Pressure</th>
            <td>1021.03 hPa</td>
          </tr>
          <tr>
            <th>Dew Point</th>
            <td>37.18¬∞F</td>
          </tr>
          <tr>
            <th>Visibility</th>
            <td>6.0 miles</td>
          </tr>
        </table>
      </div>
  
      <div class="card">
        <h2>Reddit</h2>
  
        <h3 class="subreddit">r/golang</h3>
        <ul class="item-list">
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhmpma/github_ethicalgophergofortify_basic_firewall_for/" target="_blank">GitHub - EthicalGopher/GoFortify: basic firewall for websites</a>
            <div class="item-content"><table> <tr><td> <a href="https://www.reddit.com/r/golang/comments/1rhmpma/github_ethicalgophergofortify_basic_firewall_for/">  </a> </td><td> <!-- SC_OFF --><div class="md"><p>&#x200B;</p> <p>I‚Äôve been working on a project called GoFortify. It‚Äôs a lightweight reverse proxy written in Go that inspects incoming HTTP traffic before forwarding it to a backend service.</p> <p>Right now it can:</p> <p>Detect common SQL injection patterns</p> <p>Detect basic XSS payloads</p> <p>Apply IP-based rate limiting</p> <p>Show live traffic and blocked requests in a terminal UI (built with Bubble Tea)</p> <p>Log security events in structured JSON</p> <p>You can run it in front of any local backend and it starts inspecting and proxying traffic immediately.</p> <p>I built it to learn more about reverse proxies, HTTP internals, and building security tooling in Go. I‚Äôd really appreciate feedback on the architecture, detection approach (regex-based), and any obvious security gaps.</p> <p>Repo:</p> <p><a href="https://github.com/EthicalGopher/GoFortify">Repo Link</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Chomuhrick"> /u/Chomuhrick </a> <br/> <span><a href="https://github.com/EthicalGopher/GoFortify">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhmpma/github_ethicalgophergofortify_basic_firewall_for/">[comments]</a></span> </td></tr></table></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhlqnj/i_built_a_go_rest_api_boilerplate_on_pure_nethttp/" target="_blank">I built a Go REST API boilerplate on pure net/http ‚Äî no frameworks, just structure</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I‚Äôm a Node.js developer who got tired of chasing the JS ecosystem ‚Äî new framework every quarter, breaking changes every major version, half your node_modules deprecated before your project ships. Go‚Äôs stability sold me, so I built something in between: <strong>actual separation of concerns without the overengineering</strong>.</p> <h1>What it does</h1> <p><strong>1. Separates business logic from HTTP/database</strong> ‚Äî your domain code imports nothing. No framework<br/> types leaking into your services. When you want to swap SQLite for Postgres, you change one adapter file. Your business logic doesn‚Äôt know and doesn‚Äôt care.</p> <pre><code>domain/user/ ‚Üí pure Go: entities, interfaces, service logic adapter/user/ ‚Üí HTTP handlers + SQLite repo (implements domain interface) infra/ ‚Üí router, db, config, logging, telemetry cmd/http/main.go ‚Üí wires everything (84 lines, no magic) </code></pre> <p><strong>2. The router is just net/http with extras</strong> ‚Äî a ~110 LOC wrapper over <code>http.ServeMux</code> that adds<br/> middleware chaining and route groups. That‚Äôs it. No custom context, no framework lock-in.</p> <pre><code> r := router.NewRouter() r.Prefix(&quot;/api&quot;) r.Use(logger.Middleware) r.Use(recovery.Middleware) r.Group(&quot;/users&quot;, userHandler.RegisterRoutes) // groups support scoped middleware + nesting </code></pre> <p><strong>3. 9 direct dependencies -</strong> SQLite (pure Go, zero CGO), validator, OTEL, Prometheus, Swagger. Every one earns its place.</p> <p><strong>4. Database is detachable via sqlc</strong> ‚Äî write SQL, get type-safe Go code. No ORM, no reflection. The<br/> generated code sits behind a domain interface, so swapping databases means writing a new adapter<br/> ‚Äî zero changes to business logic.</p> <p><strong>5. Observability isn‚Äôt a TODO</strong> ‚Äî OpenTelemetry tracing, Prometheus metrics, structured logging with<br/> trace correlation all wired in. make obs/up starts Grafana + Tempo + Loki + Prometheus locally.</p> <p><strong>6. Dev experience included:</strong></p> <p>make dev # hot-reload server<br/> make check # fmt + vet + 39 linters + tests<br/> make sqlc # regenerate type-safe DB code<br/> make swagger # regenerate OpenAPI docs<br/> make perf # k6 load tests via Docker<br/> make obs/up # full Grafana observability stack</p> <p>All dev tools managed via go tool ‚Äî no global installs.</p> <p><strong>7. Claude agents + skills added for later feature development with strict rules</strong></p> <p>GitHub: <a href="https://github.com/tung-dnt/golang-boilerplate">https://github.com/tung-dnt/golang-boilerplate</a></p> <p>Looking for feedback ‚Äî especially on the router design and the architecture boundaries. Is this<br/> the right level of structure, or still too much/too little?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Tungdayhehe"> /u/Tungdayhehe </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhlqnj/i_built_a_go_rest_api_boilerplate_on_pure_nethttp/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhlqnj/i_built_a_go_rest_api_boilerplate_on_pure_nethttp/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhk451/why_does_everything_gets_removed_here/" target="_blank">Why does everything gets removed here?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>[ Removed by moderator ]</p> <p>Sorry, this post has been removed by moderators of <a href="/r/golang">r/golang</a>.</p> <p>...</p> <p>Seriously, what is wrong with the mods of this community?</p> <p>I keep finding interesting posts, leaving them open to read later, and when I come back - gone. No explanation. No discussion. Just removed.</p> <p>Anything that mentions another language alongside Go? Removed. Any criticism - even constructive, technical criticism? Removed. Comparisons? Tradeoffs? Real-world frustrations? Also removed.</p> <p>What&#39;s the point of a discussion forum where discussion itself is unwelcome?</p> <p>I&#39;m not talking about spam or low-effort posts - obviously that should be moderated. But when normal conversations disappear just because they&#39;re not pure praise, it stops feeling like a community and starts feeling like a curated promo page.</p> <p>People learn by comparing tools. People improve things by criticizing them. That&#39;s how engineering works. Pretending a language has no downsides doesn&#39;t make it better - it just makes the conversation worse.</p> <p>Threads are vanishing faster than anyone can actually participate in them. It&#39;s exhausting.</p> <p>I want to enjoy reading and participating here, but what&#39;s the point if everything remotely interesting gets wiped?</p> <p>Anyone else noticing this, or is it just me?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/o82"> /u/o82 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhk451/why_does_everything_gets_removed_here/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhk451/why_does_everything_gets_removed_here/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhianu/i_built_godatefns_140_date_utility_functions_for/" target="_blank">I built go-date-fns: 140+ date utility functions for Go, inspired by date-fns</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hey <a href="https://www.reddit.com/r/golang/">r/golang</a></p> <p>I got tired of writing boilerplate date logic in every Go project, so I built</p> <p>go-date-fns ‚Äî a comprehensive date utility library inspired by the popular</p> <p>JavaScript date-fns library.</p> <p>**What it does:**</p> <p>- 140+ pure, immutable functions</p> <p>- Business days, ISO weeks, interval utilities</p> <p>- FormatDistance (&quot;about 2 hours ago&quot;)</p> <p>- Timezone-aware operations</p> <p>- Zero external dependencies</p> <p>- 100% test coverage</p> <p>**Simple example:**</p> <p>```go</p> <p>import &quot;github.com/chmenegatti/go-date-fns/dateutils&quot;</p> <p>// Add 5 business days (skips weekends)</p> <p>deadline := dateutils.AddBusinessDays(time.Now(), 5)</p> <p>// Human-readable relative time</p> <p>fmt.Println(dateutils.FormatDistanceToNow(deadline, &amp;dateutils.FormatDistanceOptions{AddSuffix: true}))</p> <p>// &quot;in 5 days&quot;</p> <p>Coming from JavaScript? The API will feel very familiar.</p> <p>GitHub: <a href="https://github.com/chmenegatti/go-date-fns">https://github.com/chmenegatti/go-date-fns</a> <br/> pkg.go.dev: <a href="https://pkg.go.dev/github.com/chmenegatti/go-date-fns">https://pkg.go.dev/github.com/chmenegatti/go-date-fns</a></p> <p>Happy to hear feedback!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/LazyDog80"> /u/LazyDog80 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhianu/i_built_godatefns_140_date_utility_functions_for/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhianu/i_built_godatefns_140_date_utility_functions_for/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhhv7m/data_range_intersection_lib/" target="_blank">Data Range intersection Lib</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Here a range intersection library for go that supports generics: <a href="https://github.com/akalinux/span-tools">https://github.com/akalinux/span-tools</a></p> <h1>Span-Tools</h1> <p><a href="https://github.com/akalinux/span-tools#span-tools"></a></p> <p>Implements the universal span intersection algorithm. The algorithm represents a unified way to find intersections and overlaps of &quot;one dimensional spans&quot; of any data type. The package is built around the SpanUtil[E any] struct, and the manipulation of the SpanBoundry[E any] interface.</p> <p>The SpanUtils[E any] struct requires 2 methods be passed to the constructor in order to implement the algorithm:</p> <ul> <li>A &quot;Compare&quot; function see: <a href="https://pkg.go.dev/cmp#Compare">cmp.Compare</a> for more details.</li> <li>A &quot;Next&quot; function, takes a given value and returns next value. The next value must be greater than the input value</li> </ul> <p>The algorithm is primarily implemented by 3 methods of the SpanUtil[E] struct:</p> <ul> <li>FirstSpan, finds the initial data span intersection.</li> <li>NextSpan, finds all subsequent data span intersections.</li> <li>CreateOverlapSpan, finds the most common intersection of all overlapping spans.</li> </ul> <p>Other features of this package:</p> <ul> <li>Provide ways to consolidate overlaps.</li> <li>Iterate through intersections of multiple data sets.</li> </ul> <h1>Basic Example</h1> <p><a href="https://github.com/akalinux/span-tools#basic-example"></a></p> <p>In this example we will find the intersections of 3 sets of integers. The full example can be found: <a href="https://github.com/akalinux/span-tools/blob/main/examples/example01/example01.go">here</a>.</p> <p>Example Sets:</p> <pre><code>(1,2) (2,7) (5,11) </code></pre> <p><strong>Setup the package and imports:</strong></p> <p>We will need to import our &quot;st&quot; package along with the &quot;fmt&quot; and &quot;cmp&quot; packages in order to process the example data sets.</p> <pre><code>import ( &quot;github.com/akalinux/span-tools&quot; &quot;fmt&quot; &quot;cmp&quot; ) </code></pre> <p><strong>Create our SpanUtil[E] instance:</strong></p> <p>We will use the factory interface NewSpanUtil to generate our SpanUtil[int] instance for these examples. This ensures that the Validate and Sort options are by set to true for all base examples.</p> <pre><code>var u=st.NewSpanUtil( // use the standard Compare function cmp.Compare, // Define our Next function func(e int) int { return e+1}, ) </code></pre> <p><strong>Find our the initial SpanBoundry intersection:</strong></p> <p>We need to find the initial intersection, before we can iterate through of these data sets. The initial SpanBoundry is found by making a call to u.FirstSapn(list).</p> <pre><code>// Create our initial span var span,ok=u.FirstSpan(list) // Denote our overlap set position var count=0 </code></pre> <p><strong>Iterate through all of our SpanBoundry intersections:</strong></p> <p>We can now step through each data intersection point and output the results. Each subsequent intersection is found by making a call to u.NextSpan(span,list).</p> <pre><code>for ok { // Get the indexes of the columns this overlap relates to var sources=u.GetOverlapIndexes(span,list) // output our intersection data fmt.Printf(&quot;Overlap Set: %d, Span: %v, Columns: %v\n&quot;,count,span,sources) // update our overlap set count++ // get our next set span,ok=u.NextSpan(span,list) } </code></pre> <p><strong>Resulting output:</strong></p> <pre><code>Overlap Set: 0, Span: &amp;{1 1}, Columns: &amp;[0] Overlap Set: 1, Span: &amp;{2 2}, Columns: &amp;[0 1] Overlap Set: 2, Span: &amp;{3 5}, Columns: &amp;[1 2] Overlap Set: 3, Span: &amp;{6 7}, Columns: &amp;[1 2] Overlap Set: 4, Span: &amp;{8 11}, Columns: &amp;[2] </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Obvious-Image-9688"> /u/Obvious-Image-9688 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhhv7m/data_range_intersection_lib/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhhv7m/data_range_intersection_lib/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhdj9c/pending_minimal_purego_deferred_task_scheduler_id/" target="_blank">pending: minimal pure-Go deferred task scheduler (ID debounce + cancel + graceful shutdown)</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I released pending, a tiny scheduler for in-memory deferred work in Go:</p> <p><a href="https://github.com/kahoon/pending">https://github.com/kahoon/pending</a></p> <p>Main features:</p> <ul> <li>ID-based scheduling and debouncing (reschedule same ID)</li> <li>Cancel(id)</li> <li>graceful Shutdown(ctx)</li> <li>concurrency limits: StrategyBlock / StrategyDrop</li> <li>telemetry hooks</li> <li>zero dependencies (stdlib only)</li> </ul> <p>It‚Äôs deliberately not cron syntax or persistent job storage.<br/> Target use case is process-local deferred actions.</p> <p>Would love feedback on API design and edge cases I should harden.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Hungry-Plantain-1008"> /u/Hungry-Plantain-1008 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhdj9c/pending_minimal_purego_deferred_task_scheduler_id/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhdj9c/pending_minimal_purego_deferred_task_scheduler_id/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhdfon/how_suitable_is_golang_for_building_an_ecommerce/" target="_blank">How suitable is Golang for building an eCommerce website?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hello everyone!</p> <p>How suitable is Golang for building an eCommerce website?</p> <p>I‚Äôve been searching online but haven‚Äôt found any ready-to-use frameworks or boilerplates specifically for building eCommerce websites with Golang.</p> <p>Do you have any experience building eCommerce sites with Golang?</p> <p>I‚Äôm also interested to know whether it‚Äôs possible to build both the backend and frontend using pure Golang and Go libraries only, instead of separating the frontend into another language or framework?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Worth-Leader3219"> /u/Worth-Leader3219 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhdfon/how_suitable_is_golang_for_building_an_ecommerce/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhdfon/how_suitable_is_golang_for_building_an_ecommerce/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhax97/mqtt_the_protocol_behind_every_smart_device_golang/" target="_blank">MQTT: The Protocol Behind Every Smart Device (Golang)</a>
            <div class="item-content"><table> <tr><td> <a href="https://www.reddit.com/r/golang/comments/1rhax97/mqtt_the_protocol_behind_every_smart_device_golang/">  </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/huseyinbabal"> /u/huseyinbabal </a> <br/> <span><a href="https://youtu.be/S64crfW9tQU">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhax97/mqtt_the_protocol_behind_every_smart_device_golang/">[comments]</a></span> </td></tr></table></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rhagoe/am_i_the_only_one_who_finds_mobile_testing/" target="_blank">Am I the only one who finds mobile testing genuinely demoralizing?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Six years in QA and last week I spent three hours debugging a test failure that turned out to be a 200ms animation delay on a bottom sheet ......Three hours like are you fr???</p> <p>On web that whole investigation takes minutes, you open DevTools, you see exactly what happened, you fix it and move on and that&#39;s the gap I&#39;m talking about. On web I feel like a professional. Fast feedback, reliable CI, and when something breaks the debugging experience actually respects your time but on mobile I&#39;m reverse engineering why a login flow test failed on Android but passed on iOS even though the user journey is literally identical on both platforms, and I&#39;m maintaining two completely separate suites just to cover that same flow.</p> <p>The flakiness is what really gets me though like let me tell you something so we had a payment checkout test that failed roughly 1 in 6 runs nobody touched it for months because everyone assumed it was just a flaky test it turned out that it was masking a real race condition in the order confirmation screen that eventually made it to production that&#39;s what normalizing 15% flakiness actually costs you in practice.</p> <p>I&#39;ve looked at alternatives and everything shares the same core problems just wrapped differently and nothing fundamentally changes underneath.</p> <p>So genuinely asking, is this a platform constraint, an investment problem, or have I just not found the right tool yet? Because that three hour animation debugging session is not an edge case for me, it&#39;s just a regular Tuesday.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PensionPlastic2544"> /u/PensionPlastic2544 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rhagoe/am_i_the_only_one_who_finds_mobile_testing/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rhagoe/am_i_the_only_one_who_finds_mobile_testing/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rh856c/ssh_honeypot/" target="_blank">ssh honeypot</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>A high-interaction SSH honeypot written in Go that simulates a real Ubuntu server to capture and log attacker behavior.</p> <p><a href="https://github.com/Moundher122/SSH-Honeypot">https://github.com/Moundher122/SSH-Honeypot</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/KitchenBlackberry332"> /u/KitchenBlackberry332 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rh856c/ssh_honeypot/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rh856c/ssh_honeypot/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rh5s1a/oneclick_eks_upgrades_the_reality_behind_the/" target="_blank">One-Click EKS Upgrades? The Reality Behind the Button</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Managing multiple AWS EKS clusters lifecycle without proper EOL dashboard is very difficult, here <a href="https://kubefront.net/devops/one-click-eks-upgrades-reality-behind/">blog post</a> I shared my experience,</p> <p>EKS has auto upgrades feature, but it will only update AWS control plane and AWs addons. To solve this problem, we build our own Golang Prometheus exporter for custom metrices</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Downtown-Warning6818"> /u/Downtown-Warning6818 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rh5s1a/oneclick_eks_upgrades_the_reality_behind_the/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rh5s1a/oneclick_eks_upgrades_the_reality_behind_the/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rh5ry4/gobenchdev_comparisons_of_different_stdlib/" target="_blank">gobench.dev - Comparisons of different stdlib features</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hey, I built <a href="https://gobench.dev">https://gobench.dev</a> and I am looking for some feedback.</p> <p>The purpose of the site is to compare different functions in the standard library that achieve the same result. It helps you see how they perform in terms of speed, memory usage, and allocations, across different amounts of CPU cores used. I hope this helps someone!</p> <p>Please let me know if the charts are easy to understand and if you have ideas for improvements!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MarvinJWendt"> /u/MarvinJWendt </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rh5ry4/gobenchdev_comparisons_of_different_stdlib/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rh5ry4/gobenchdev_comparisons_of_different_stdlib/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rh0q0y/jsoncanon_implementing_burgerdybvig_ieee_754/" target="_blank">json-canon: Implementing Burger-Dybvig (IEEE 754 ‚Üí shortest decimal) in Go for RFC 8785</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Full article: [Shortest Round-Trip: Implementing IEEE 754 to Decimal Conversion in Go](<a href="https://lattice-substrate.github.io/blog/2026/02/27/shortest-roundtrip-ieee754-burger-dybvig/">https://lattice-substrate.github.io/blog/2026/02/27/shortest-roundtrip-ieee754-burger-dybvig/</a>) </p> <p>This is Part 1 of a four-part series on building an RFC 8785 JSON Canonicalization library in Go ([github.com/lattice-substrate/json-canon](<a href="https://github.com/lattice-substrate/json-canon)">https://github.com/lattice-substrate/json-canon)</a>). Parts 2‚Äì4 cover the strict RFC 8259 parser, infrastructure-grade design decisions, and evidence-based release engineering. </p> <p>This article covers the hardest part: number formatting. RFC 8785 requires ECMA-262‚Äìcompatible output, which means you need the shortest decimal that round-trips to the original IEEE 754 bits, with even-digit tie-breaking. Go&#39;s `strconv.FormatFloat` is high quality but doesn&#39;t expose an ECMA-262 conformance contract, so I implemented Burger-Dybvig from scratch in 490 lines with `math/big`. Validated against 286K oracle vectors with SHA-256 pinned test data. Pure Go, zero deps. </p> <p>Happy to discuss the algorithm, the testing approach, or the design tradeoffs.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/UsrnameNotFound-404"> /u/UsrnameNotFound-404 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rh0q0y/jsoncanon_implementing_burgerdybvig_ieee_754/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rh0q0y/jsoncanon_implementing_burgerdybvig_ieee_754/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rguj4o/new_sorted_map_for_go/" target="_blank">New Sorted map for go</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Here is a link to the new sorted map I have created for go: <a href="https://github.com/akalinux/orderedmap">https://github.com/akalinux/orderedmap</a></p> <p>Performance Benchmarks are here: <a href="https://github.com/akalinux/benchmarksortedmaps">https://github.com/akalinux/benchmarksortedmaps</a></p> <p>Example showing the fuzzy logic:</p> <pre><code>kv:=omap.NewTs[string,string](cmp.Compare) // Save a value kv.Put(&quot;Hello&quot;,&quot; &quot;) kv.Put(&quot;World&quot;,&quot;!\n&quot;) // Itertor for k,v :=range kv.All { fmt.Printf(&quot;%s%s&quot;,k,v) </code></pre> <p>The resulting output will be:</p> <pre><code>&quot;Hello World!\n&quot; </code></pre> <p>We can now make things a bit smaller by removing things by a range.</p> <pre><code>// Note, both &quot;Sell&quot; and &quot;Universe&quot;, were never added to the instance, // but the between operation works on these keys any ways. kv.RemoveBetween(&quot;Sell&quot;,&quot;Zoo&quot;) // Itertor for k,v :=range kv.All() { fmt.Printf(&quot;%s%s\n&quot;,k,v) } </code></pre> <p>The resulting output will now be:</p> <pre><code>&quot;Hello \n&quot; </code></pre> <p><strong>Why this works?</strong></p> <ul> <li>The string &quot;Sell&quot; comes before the string &quot;World&quot;</li> <li>The string &quot;Zoo&quot; comes after the string &quot;World&quot;</li> </ul> <p><strong>How this works</strong></p> <p>The index lookup creates 2 values for each potential key:</p> <ul> <li>Array position, example: 0</li> <li>Offset can be any of the following: -1,0,1</li> </ul> <p>Since lookups create both an index position and offset, it becomes possible to look for the following:</p> <ul> <li>Elements before the array</li> <li>Positions between elements of the array</li> <li>Elements after the array</li> <li>Elements to overwrite</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Obvious-Image-9688"> /u/Obvious-Image-9688 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rguj4o/new_sorted_map_for_go/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rguj4o/new_sorted_map_for_go/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/golang/comments/1rgt8ps/do_you_actually_check_the_error_for_cryptorandread/" target="_blank">Do you actually check the error for crypto/rand.Read?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Title :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Existing-Search3853"> /u/Existing-Search3853 </a> <br/> <span><a href="https://www.reddit.com/r/golang/comments/1rgt8ps/do_you_actually_check_the_error_for_cryptorandread/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/golang/comments/1rgt8ps/do_you_actually_check_the_error_for_cryptorandread/">[comments]</a></span></div>
          </li>
  
        </ul>
  
        <h3 class="subreddit">r/rust</h3>
        <ul class="item-list">
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhlko8/ratic_version_010_simple_music_player/" target="_blank">Ratic version 0.1.0: simple music player</a>
            <div class="item-content">&#32; submitted by &#32; <a href="https://www.reddit.com/user/Boubou0909"> /u/Boubou0909 </a> <br/> <span><a href="/r/gnome/comments/1rhlkcw/ratic_version_010_simple_music_player/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhlko8/ratic_version_010_simple_music_player/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhl3b8/twolevel_merkle_tree_architecture_in_rust_how_one/" target="_blank">Two-level Merkle tree architecture in Rust -- how one tree proves another</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I&#39;m building a transparency log in Rust where every document gets a cryptographic receipt proving it existed. The system needs to run forever, but a single Merkle tree that grows without bound creates operational problems: unbounded slab files, no natural key rotation boundary, and no way to anchor different tree snapshots at different granularities.</p> <p>ATL Protocol solves this with a two-level architecture: short-lived <strong>Data Trees</strong> and an eternal <strong>Super-Tree</strong>. Here&#39;s the full design -- the chaining mechanism, the verification, and the cross-receipt trick that lets two independent holders prove log integrity without contacting the server.</p> <h1>The Architecture</h1> <p>Each Data Tree accumulates entries for a bounded period (configurable -- 24 hours or 100K entries). When the period ends, the tree is closed, its root hash becomes a leaf in the Super-Tree, and a fresh Data Tree starts. The Super-Tree is itself an RFC 6962 Merkle tree -- it grows by one leaf every time a Data Tree closes.</p> <p>Why not one big tree? Three reasons:</p> <ol> <li><strong>Bounded slab files.</strong> Each Data Tree maps to a fixed-size memory-mapped slab (~64 MB for 1M leaves). No multi-gigabyte files growing forever.</li> <li><strong>Key rotation.</strong> Each Data Tree gets its own checkpoint signed at close time. Rotating Ed25519 keys between trees is a natural boundary.</li> <li><strong>Anchoring granularity.</strong> RFC 3161 timestamps anchor Data Tree roots (seconds). Bitcoin OTS anchors the Super Root (hours, permanent). Different trust levels at different time scales.</li> </ol> <h1>Genesis Leaf: Chaining Trees Together</h1> <p>When a new Data Tree starts, leaf 0 is not user data. It is a genesis leaf -- a cryptographic link to the previous tree:</p> <pre><code>pub const GENESIS_DOMAIN: &amp;[u8] = b&quot;ATL-CHAIN-v1&quot;; pub fn compute_genesis_leaf_hash(prev_root_hash: &amp;Hash, prev_tree_size: u64) -&gt; Hash { let mut hasher = Sha256::new(); hasher.update([LEAF_PREFIX]); hasher.update(GENESIS_DOMAIN); hasher.update(prev_root_hash); hasher.update(prev_tree_size.to_le_bytes()); hasher.finalize().into() } SHA256(0x00 || &quot;ATL-CHAIN-v1&quot; || prev_root_hash || prev_tree_size_le) </code></pre> <p>The domain separator <code>ATL-CHAIN-v1</code> prevents collision between genesis leaves and regular data leaves -- different hash domain, no overlap in input space. The <code>0x00</code> prefix is the standard RFC 6962 leaf prefix. The genesis leaf occupies a regular leaf slot in the Data Tree. The Merkle tree does not need special handling for it -- the distinction between &quot;genesis&quot; and &quot;data&quot; exists only in the semantic layer, not in the tree structure.</p> <p>Binding both <code>prev_root_hash</code> and <code>prev_tree_size</code> means the chain breaks if the operator rewrites the previous tree in any way -- changing, adding, or removing entries. Any verifier holding a receipt from the previous tree detects the inconsistency.</p> <h1>Super-Tree Inclusion Verification</h1> <p>The Super-Tree reuses the same <code>verify_inclusion</code> function as Data Trees. No special proof algorithms needed:</p> <pre><code>pub fn verify_super_inclusion(data_tree_root: &amp;Hash, super_proof: &amp;SuperProof) -&gt; AtlResult&lt;bool&gt; { if super_proof.super_tree_size == 0 { return Err(AtlError::InvalidTreeSize { size: 0, reason: &quot;super_tree_size cannot be zero&quot;, }); } if super_proof.data_tree_index &gt;= super_proof.super_tree_size { return Err(AtlError::LeafIndexOutOfBounds { index: super_proof.data_tree_index, tree_size: super_proof.super_tree_size, }); } let expected_super_root = super_proof.super_root_bytes()?; let inclusion_path = super_proof.inclusion_path_bytes()?; let inclusion_proof = InclusionProof { leaf_index: super_proof.data_tree_index, tree_size: super_proof.super_tree_size, path: inclusion_path, }; verify_inclusion(data_tree_root, &amp;inclusion_proof, &amp;expected_super_root) } </code></pre> <p>Two structural checks before any crypto work: tree size cannot be zero, index cannot exceed size. Malformed proofs rejected before touching hash operations.</p> <h1>Consistency to Origin: Always from Size 1</h1> <p>Every receipt carries a consistency proof from Super-Tree size 1 to the current size. The <code>from_size</code> is always 1 -- this is a deliberate design choice:</p> <pre><code>pub fn verify_consistency_to_origin(super_proof: &amp;SuperProof) -&gt; AtlResult&lt;bool&gt; { // ... if super_proof.super_tree_size == 1 { if super_proof.consistency_to_origin.is_empty() { return Ok(use_constant_time_eq(&amp;genesis_super_root, &amp;super_root)); } return Err(AtlError::InvalidProofStructure { reason: format!( &quot;consistency_to_origin must be empty for super_tree_size 1, got {} hashes&quot;, super_proof.consistency_to_origin.len() ), }); } let consistency_proof = ConsistencyProof { from_size: 1, to_size: super_proof.super_tree_size, path: consistency_path, }; verify_consistency(&amp;consistency_proof, &amp;genesis_super_root, &amp;super_root) } </code></pre> <p>Why always from size 1? Because it makes every receipt self-contained. Each receipt independently proves its relationship to the origin. Verification is O(1) receipts, not O(N). Any single receipt, in isolation, proves that the entire log history up to that point is an append-only extension of genesis.</p> <p>The alternative -- proving consistency from the previous receipt&#39;s size -- would require sequential verification: to verify receipt C, you need receipt B, and to verify receipt B, you need receipt A, all the way back.</p> <p>The cost is a slightly longer proof path. For a Super-Tree with a million Data Trees: 40 hashes = 1280 bytes. Negligible.</p> <h1>Cross-Receipt Verification: The Payoff</h1> <p>This is why the two-level architecture is worth the complexity. Two people with receipts from different points in time can independently verify log integrity -- no server, no communication between them:</p> <pre><code>pub fn verify_cross_receipts( receipt_a: &amp;Receipt, receipt_b: &amp;Receipt, ) -&gt; CrossReceiptVerificationResult { // Step 1: Both receipts must have super_proof let super_proof_a = receipt_a.super_proof.as_ref()?; let super_proof_b = receipt_b.super_proof.as_ref()?; // Step 2: Same genesis? let genesis_a = super_proof_a.genesis_super_root_bytes()?; let genesis_b = super_proof_b.genesis_super_root_bytes()?; if !use_constant_time_eq(&amp;genesis_a, &amp;genesis_b) { // Different logs entirely return result; } // Step 3: Both consistent with genesis? let consistency_a = verify_consistency_to_origin(super_proof_a); let consistency_b = verify_consistency_to_origin(super_proof_b); match (consistency_a, consistency_b) { (Ok(true), Ok(true)) =&gt; { result.history_consistent = true; } // ... } result } </code></pre> <p>Three checks, no server required:</p> <ol> <li><strong>Same genesis?</strong> If <code>genesis_super_root</code> differs, different log instances.</li> <li><strong>Receipt A consistent with genesis?</strong> RFC 9162 consistency proof from size 1 to A&#39;s snapshot.</li> <li><strong>Receipt B consistent with genesis?</strong> Same check for B.</li> </ol> <p>If both are consistent with the same genesis, then by transitivity of Merkle consistency, the history between them was not modified. Consistency proofs are transitive: if size 50 is consistent with size 1, and size 100 is consistent with size 1, then size 100 is consistent with size 50. Any modification to the first 50 Data Trees breaks at least one proof.</p> <p>No communication. No server. No trusted third party. Two receipts, one function call.</p> <h1>The Full Verification Chain</h1> <p>For a single receipt, five levels build on each other:</p> <ol> <li><strong>Entry:</strong> document hash matches <code>payload_hash</code></li> <li><strong>Data Tree:</strong> Merkle inclusion proof from leaf to Data Tree root</li> <li><strong>Super-Tree inclusion:</strong> inclusion proof from Data Tree root to Super Root</li> <li><strong>Super-Tree consistency:</strong> consistency proof from genesis to current Super Root</li> <li><strong>Anchors:</strong> TSA on Data Tree root, Bitcoin OTS on Super Root</li> </ol> <p>Each level uses standard RFC 9162 Merkle proofs. The entire verification stack is built from two primitives: &quot;this leaf is in this tree&quot; and &quot;this smaller tree is a prefix of this larger tree.&quot; Everything else is composition.</p> <p>Source: <a href="https://github.com/evidentum-io/atl-core">github.com/evidentum-io/atl-core</a> (Apache-2.0)</p> <p>Full post: <a href="https://atl-protocol.org/blog/super-tree-architecture">atl-protocol.org/blog/super-tree-architecture</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/d_zatona"> /u/d_zatona </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rhl3b8/twolevel_merkle_tree_architecture_in_rust_how_one/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhl3b8/twolevel_merkle_tree_architecture_in_rust_how_one/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhjsat/i_used_tauri_and_rust_to_build_a_native_windows/" target="_blank">I used Tauri and Rust to build a native Windows Git context menu that replaces heavy Electron GUI clients. (OpenSource)</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hey <a href="/r/rust">r/rust</a>,</p> <p>I wanted to share a desktop utility I recently built called <strong>GitPop</strong>. It‚Äôs a Windows File Explorer extension that brings a Git UI directly to your right-click context menu.</p> <p><a href="https://github.com/vinzify/gitpop">https://github.com/vinzify/gitpop</a></p> <h1>Why Rust and Tauri?</h1> <p>A context menu popup needs to open instantly. I initially looked at Electron, but shipping a 100MB+ Chromium instance just to show a tiny Git status window felt unacceptable. Using <strong>Tauri v2</strong> let me keep the binary size small and the startup time nearly instantaneous.</p> <h1>A few fun implementation details</h1> <h1>OS integration (registry binding)</h1> <p>I used the <code>winreg</code> crate to dynamically find the app‚Äôs executable and bind it to the <code>Directory\\Background\\shell</code> registry keys during setup.</p> <h1>Headless Git (no libgit2)</h1> <p>Instead of linking <code>libgit2</code> (which can be a headache and often ignores the user‚Äôs global <code>.gitconfig</code>), the Rust backend spawns child processes to run native Git CLI binaries.</p> <p>To prevent Windows CMD boxes from flashing on the screen, I had to use <code>CommandExt</code> plus the <code>CREATE_NO_WINDOW</code> flag.</p> <h1>Local LLMs for commit messages</h1> <p>I implemented a feature that pipes <code>git diff</code> output to a local <strong>Ollama</strong> instance (via <code>reqwest</code>) to auto-generate commit messages entirely on-device, keeping source code private.</p> <h1>UI quirks</h1> <p>Building a transparent, glassmorphism UI on Windows 11 WebView2 had a few quirky panics, but the Tauri v2 APIs handled it cleanly once configured.</p> <p>The source code is fully open-source if anyone wants to see how the context-menu registry binding or hidden child processes were implemented!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/twinalien"> /u/twinalien </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rhjsat/i_used_tauri_and_rust_to_build_a_native_windows/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhjsat/i_used_tauri_and_rust_to_build_a_native_windows/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhdp64/building_a_performant_editor_for_zaku_with_gpui/" target="_blank">Building a performant editor for Zaku with GPUI</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>First of all, this wouldn&#39;t be possible or would probably take months if not years (assuming i won&#39;t give up before) without Zed&#39;s source code, so thanks to all the talented folks at Zed, a lot of the things i did is inspired by how Zed does things for their own editor.</p> <p>I built it on top of Zed&#39;s text crate which uses rope and sum tree underneath, there&#39;s a great read on their blog:</p> <p><a href="https://zed.dev/blog/zed-decoded-rope-sumtree">https://zed.dev/blog/zed-decoded-rope-sumtree</a></p> <p>The linked YouTube video is also highly worth watching.</p> <p>It doesn&#39;t have all the bells and whistles like LSP, syntax highlighting, folding, text wrap, inlay hints, gutter, etc. coz i don&#39;t need it for an API client at least for now, i&#39;ll add syntax highlighting &amp; gutter later though.</p> <p><a href="https://github.com/buildzaku/zaku/pull/17">https://github.com/buildzaku/zaku/pull/17</a></p> <p>This is just a showcase post, maybe i&#39;ll make a separate post or write a blog on my experience in detail. Right now i&#39;m stress testing it with large responses and so far it doesn&#39;t even break sweat at 1.5GB, it&#39;s able to go much higher but there&#39;s an initial freeze which is my main annoyance. also my laptop only has 16GB memory so there&#39;s that.</p> <p>Postman, Insomnia and Bruno seemed to struggle at large responses and started stuttering, Postman gives up and puts a hard limit after 50MB, Insomnia went till 100MB, while Bruno crashed at 80MB</p> <p>Repository:</p> <p><a href="https://github.com/buildzaku/zaku">https://github.com/buildzaku/zaku</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/errmayank"> /u/errmayank </a> <br/> <span><a href="https://i.redd.it/6h6mrb9etamg1.gif">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhdp64/building_a_performant_editor_for_zaku_with_gpui/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhcaxs/another_minimal_quantity_library_in_rust_mainly/" target="_blank">Another minimal quantity library in rust (mainly for practice, feedback welcome!)</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Another quantity library in rust... I know there are many, and they are probably better than mine (i.e. uom). However, I wanted to practice some aspects of Rust including procedural macros. I learned a lot from this project!</p> <p>Feedback is encouraged and very much welcome!</p> <p><a href="https://github.com/Audrique/quantity-rs/tree/main">https://github.com/Audrique/quantity-rs/tree/main</a></p> <p>Me rambling:</p> <p>I only started properly working as a software engineer around half a year ago and have been dabbling in Rust over a year. As I use Python at my current job, my main question for you is if I am doing stuff a &#39;non-idiomatic&#39; way. For example, I was searching on how I could write interface tests for every struct that implements the &#39;Quantity&#39; trait in my library. In Python, you can write one set of interface tests and let implementation tests inherit it, thus running the interface tests for each implementation. I guess it is not needed in Rust since you can&#39;t override traits?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/EveningLimp3298"> /u/EveningLimp3298 </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rhcaxs/another_minimal_quantity_library_in_rust_mainly/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhcaxs/another_minimal_quantity_library_in_rust_mainly/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhc7ac/published_my_first_crate_in_response_to_a_nasty/" target="_blank">Published my first crate - in response to a nasty production bug I'd caused</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Wrote my first crate.</p> <p>I&#39;d been trying to debug this fiendishly hard to reproduce head of line blocking issue which only occured when people disconnected from the corporate VPN I work behind.</p> <p>So I thought, how can I do liveness checks in websockets better? What are all the gotchas? As it turns out, there&#39;s quite a few, and I did a bit of a dive into networking to try and cover as many edge cases as possible.</p> <p>Basically I made the mistake of running without strict liveness checks because the websocket is an absolute firehose of market data and was consumed by browsers and regular apps. But I also had multiple clients and I couldn&#39;t just add ping-ponging after the release otherwise I&#39;d start disconnecting clients who haven&#39;t implemented that. So I&#39;d released my way into a corner and needed to dig my way out.</p> <p>Basically provides the raw socket with an axum request, and a little write up on sane settings.</p> <p><a href="https://crates.io/crates/axum-socket-backpressure">https://crates.io/crates/axum-socket-backpressure</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/sonthonaxrk"> /u/sonthonaxrk </a> <br/> <span><a href="https://crates.io/crates/axum-socket-backpressure">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhc7ac/published_my_first_crate_in_response_to_a_nasty/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhc5kq/fastdedup_rust_dataset_deduplication_vs_python/" target="_blank">fastdedup: Rust dataset deduplication vs Python ‚Äì 2:55 vs 7:55, 688MB vs 22GB RAM on 15M records</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I&#39;ve been working on a Rust CLI for dataset deduplication and wanted to share benchmark results. Ran on FineWeb sample-10BT (14.8M records, 29GB) on a single machine.</p> <p><strong>Exact dedup vs DuckDB + SHA-256</strong></p> <table><thead> <tr> <th align="left">fastdedup</th> <th align="left">DuckDB</th> </tr> </thead><tbody> <tr> <td align="left">Wall clock</td> <td align="left"><strong>2:55</strong></td> </tr> <tr> <td align="left">Peak RAM</td> <td align="left"><strong>688 MB</strong></td> </tr> <tr> <td align="left">CPU cores</td> <td align="left">1</td> </tr> <tr> <td align="left">Records/sec</td> <td align="left">~85,000</td> </tr> <tr> <td align="left">Duplicates removed</td> <td align="left">51,392</td> </tr> </tbody></table> <p>2.7x faster, 32x less RAM, on a single core vs 4+. Duplicate counts match exactly.</p> <p><strong>Fuzzy dedup (MinHash + LSH) vs datatrove</strong></p> <table><thead> <tr> <th align="left">fastdedup</th> <th align="left">datatrove</th> </tr> </thead><tbody> <tr> <td align="left">Wall clock</td> <td align="left"><strong>36:44</strong></td> </tr> <tr> <td align="left">Peak RAM</td> <td align="left">23 GB</td> </tr> <tr> <td align="left">Completed</td> <td align="left">Y</td> </tr> <tr> <td align="left">Duplicates removed</td> <td align="left">105,044 (0.7%)</td> </tr> </tbody></table> <p>datatrove&#39;s stage 1 alone ran for 3h50m and I killed it. The bottleneck turned out to be spaCy word tokenization on every document before shingling ‚Äî fastdedup uses character n-grams directly which is significantly cheaper.</p> <p><strong>On the RAM trade-off:</strong> 23GB vs 1.1GB is a real trade-off, not a win. datatrove streams to disk; fastdedup holds the LSH index in memory for speed.</p> <p><strong>Honest caveats</strong></p> <ul> <li>Fuzzy dedup needs ~23GB RAM at this scale ‚Äî cloud workload, not a laptop workload</li> <li>datatrove is built for distributed execution, <code>tasks=1</code> isn&#39;t its intended config ‚Äî this is how someone would run it locally</li> </ul> <p>Demo: <a href="https://huggingface.co/spaces/wapplewhite4/fastdedup-demo">https://huggingface.co/spaces/wapplewhite4/fastdedup-demo</a></p> <p>Repo/page: <a href="https://github.com/wapplewhite4/fastdedup">https://github.com/wapplewhite4/fastdedup</a></p> <p>TUI</p> <p><a href="https://preview.redd.it/ju54psu3iamg1.png?width=1362&amp;format=png&amp;auto=webp&amp;s=de8abbe971ddd03366627d14a550424c10682222">TUI for fastdedup</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/wapplewhite4"> /u/wapplewhite4 </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rhc5kq/fastdedup_rust_dataset_deduplication_vs_python/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhc5kq/fastdedup_rust_dataset_deduplication_vs_python/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhc2ce/vector_and_semantic_search_in_stoolap/" target="_blank">Vector and Semantic Search in Stoolap</a>
            <div class="item-content">&#32; submitted by &#32; <a href="https://www.reddit.com/user/Competitive-Weird579"> /u/Competitive-Weird579 </a> <br/> <span><a href="https://stoolap.io/blog/2026/02/27/vector-and-semantic-search-in-sql/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhc2ce/vector_and_semantic_search_in_stoolap/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rhb97r/is_there_any_significant_performance_cost_to/" target="_blank">Is there any significant performance cost to using `array.get(idx).ok_or(Error::Whoops)` over `array[idx]`?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>And is `array.get(idx).ok_or(Error::Whoops)` faster than checking against known bounds explicitly with an `if` statement? </p> <p>I&#39;m doing a lot of indexing that doesn&#39;t lend itself nicely to an iterator. I suppose I could do a performance test, but I figured someone probably already knows the answer.</p> <p>Thanks in advance &lt;3</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Perfect-Junket-165"> /u/Perfect-Junket-165 </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rhb97r/is_there_any_significant_performance_cost_to/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rhb97r/is_there_any_significant_performance_cost_to/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rh9tj5/i_built_a_1_gibs_file_encryption_cli_using_io/" target="_blank">I built a 1 GiB/s file encryption CLI using io_uring, O_DIRECT, and a lock-free triple buffer</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hey <a href="/r/rust">r/rust</a>,</p> <p>I got frustrated with how slow standard encryption tools (like GPG or age) get when you throw a massive 50GB database backup or disk image at them. They are incredibly secure, but their core ciphers are largely single-threaded, usually topping out around 200-400 MiB/s.</p> <p>I wanted to see if I could saturate a Gen4 NVMe drive while encrypting, so I built <strong>Concryptor</strong>.</p> <p>GitHub: <a href="https://github.com/FrogSnot/Concryptor">https://github.com/FrogSnot/Concryptor</a></p> <p>I started out just mapping files into memory, but to hit multi-gigabyte/s throughput without locking up the CPU or thrashing the kernel page cache, the architecture evolved into something pretty crazy:</p> <ul> <li><strong>Lock-Free Triple-Buffering:</strong> Instead of using async MPSC channels (which introduced severe lock contention on small chunks), I built a 3-stage rotating state machine. While io_uring writes batch N-2 to disk, Rayon encrypts batch N-1 across all 12 CPU cores, and io_uring reads batch N.</li> <li><strong>Zero-Copy O_DIRECT:</strong> I wrote a custom 4096-byte aligned memory allocator using std::alloc. This pads the header and chunk slots so the Linux kernel can bypass the page cache entirely and DMA straight to the drive.</li> <li><strong>Security Architecture:</strong> It uses ring for assembly-optimized AES-256-GCM and ChaCha20-Poly1305. To prevent chunk-reordering attacks, it uses a TLS 1.3-style nonce derivation (base_nonce XOR chunk_index).</li> <li><strong>STREAM-style AAD:</strong> The full serialized file header (which contains the Argon2id parameters, salt, and base nonce) plus an is_final flag are bound into every single chunk&#39;s AAD. This mathematically prevents truncation and append attacks.</li> </ul> <p>It reliably pushes <strong>1+ GiB/s</strong> entirely CPU-bound, and scales beautifully with cores.</p> <p>The README has a massive deep-dive into the binary file format, the memory alignment math, and the threat model. I&#39;d love for the community to tear into the architecture or the code and tell me what I missed.</p> <p>Let me know what you think!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/supergari"> /u/supergari </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rh9tj5/i_built_a_1_gibs_file_encryption_cli_using_io/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rh9tj5/i_built_a_1_gibs_file_encryption_cli_using_io/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rh8w41/servo_v005_released/" target="_blank">Servo v0.0.5 released</a>
            <div class="item-content">&#32; submitted by &#32; <a href="https://www.reddit.com/user/Right-Grapefruit-507"> /u/Right-Grapefruit-507 </a> <br/> <span><a href="https://github.com/servo/servo/releases/tag/v0.0.5">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rh8w41/servo_v005_released/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rh7rxu/oken_a_small_ssh_wrapper_with_a_fuzzy_host_picker/" target="_blank">oken ‚Äî a small SSH wrapper with a fuzzy host picker</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I got tired of typing hostnames from memory so I put together oken. Run it with no args and you get a fuzzy picker over all your saved hosts, sorted by recency. Prefix your search with # to filter by tag ‚Äî handy when you have a bunch of prod/staging/dev hosts and just want the right one fast.</p> <p>Everything else (auto-reconnect, tunnel profiles, prod warnings) is just bonus. It wraps your system ssh so all existing flags and configs work unchanged ‚Äî you can even alias ssh=oken if you want it everywhere without thinking about it.</p> <p>Written in Rust, the binary is under 2.5MB with no runtime overhead ‚Äî it just execs your system ssh once it knows where to connect.</p> <p>GitHub: <a href="https://github.com/linkwithjoydeep/oken">https://github.com/linkwithjoydeep/oken</a></p> <p>If you end up using it, a star goes a long way. And if something&#39;s broken or you want a feature, feel free to open an issue.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/toxic2soul"> /u/toxic2soul </a> <br/> <span><a href="https://github.com/linkwithjoydeep/oken">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rh7rxu/oken_a_small_ssh_wrapper_with_a_fuzzy_host_picker/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rh7lfe/life_outside_tokio_success_stories_with_compio_or/" target="_blank">Life outside Tokio: Success stories with Compio or io_uring runtimes</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Are io_uring based async runtimes a lost cause?</p> <p>This is a space to discuss about async solutions outside epoll based design, what you have been doing with compio? How much performing it is compared with tokio? Which is your use case?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/rogerara"> /u/rogerara </a> <br/> <span><a href="https://www.reddit.com/r/rust/comments/1rh7lfe/life_outside_tokio_success_stories_with_compio_or/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rh7lfe/life_outside_tokio_success_stories_with_compio_or/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/rust/comments/1rgzhhl/searching_1gb_json_on_a_phone_44s_to_18s_a/" target="_blank">Searching 1GB JSON on a phone: 44s to 1.8s, a journey through every wrong approach</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><h1>EDIT / UPDATE:</h1> <p>After further investigation with the <code>memchr</code> author <a href="https://www.reddit.com/user/burntsushi/">burntsushi </a>:</p> <p><strong>The results were specific to running inside an Android app (shared library).</strong> When I compiled the same benchmark as a standalone binary and ran it directly on the same device, Finder was actually <strong>3.4x faster</strong> than FinderRev ‚Äî consistent with expected behavior.</p> <pre><code>Standalone binary on S23 Ultra (1GB real JSON, mmap&#39;d): Finder::find 28.3ms FinderRev::rfind 96.4ms (3.4x slower) </code></pre> <p>The difference between my app and the standalone binary might be related to how Rust compiles shared libraries (cdylib with PIC) vs standalone executables ‚Äî possibly affecting SIMD inlining or dispatch. <strong>But we haven&#39;t confirmed the exact root cause yet.</strong></p> <p>--------------------------------------------------</p> <h1>UPDATE2 (THE PLOT TWIST):</h1> <p><strong>I found the root cause of the 150x slowdown. And I am an absolute idiot.</strong> ü§¶‚Äç‚ôÇÔ∏è</p> <p>I spent the entire day benchmarking CPU frequencies, checking memory maps, and building a standalone JNI benchmark app to prove that Android was killing SIMD performance.</p> <p>The actual reason?<br/> <strong>My standalone binary was compiled in</strong> <code>--release</code><strong>. My Android JNI library was secretly compiling in</strong> <code>debug</code> <strong>mode without optimizations.</strong></p> <p>Once I fixed the compiler profile, <code>Finder::find</code> dropped from 4.2 seconds to ~30ms on the phone. The SIMD degradation doesn&#39;t exist. It was just me experiencing the sheer, unoptimized horror of Debug-mode Rust on a 1GB JSON file.</p> <p><strong>Huge apologies to</strong> <a href="https://www.reddit.com/user/burntsushi/"><strong>burntsushi</strong></a> for raising an issue and questioning his crate when the problem was entirely my own build config!</p> <p>Leaving this post up as a monument to my own stupidity and a reminder to always check your <code>opt-level</code>. Thank you all for the upvotes on my absolute hallucination of a bug! </p> <p>--------------------------------------------------</p> <p>Follow-up to my <a href="https://www.reddit.com/r/rust/comments/1qctgu3/rust_on_android_handling_1gb_json_files_with/">post from a month ago</a> about handling 1GB+ JSON on Android with Rust via JNI.</p> <p><strong>Before the roasting starts, yes I know, gigabyte JSON files shouldnt exist.</strong> People should fix their pipelines, use a database, normalize things. You&#39;re right. But this whole thing started as a &quot;can I even do this on a phone?&quot; challenge, and somewhere along the way I fell into the rabbit hole and just kept going. First app, solo dev, having way too much fun to stop.</p> <p>So I was working on a search position indicator, a small status bar at the top that shows where the scan is in the file, kind of like a timeline. While testing it on a 1GB JSON I noticed the forward search took <strong>44 seconds</strong>. Fourty four. On a flagship phone. Meanwhile the backward search, which I already had using <code>FinderRev</code>, was done in about 2 seconds. Same file, same query, same everything. That drove me absolutely crazy.</p> <p>First thing I tried was switching to <code>memmem::Finder</code>, same thing I was already using for the COUNT feature. That brought it down to about 9 seconds, big improvement, but I still couldnt understand why backward was 5 times faster on the exact same data. That gap kept bugging me.</p> <p>Here&#39;s the full journey from there.</p> <p><strong>The original, memchr on the first byte, 44 seconds</strong></p> <p>This was the code that started everything. <code>memchr2</code> anchored on the first byte of the query, whatever that byte happend to be. No frequency analysis, nothing smart. In a 1GB JSON with millions of repeated keys and values, common bytes show up literally everywhere. The scanner was stopping billions of times at false positives, checking each one, moving on, stopping again.</p> <p><strong>memmem::Finder with SIMD Two-Way, 9.4 seconds</strong></p> <p>Switched to the proper algorithm. Good improvement over 44s but still nowhere close to the 1.9 seconds that <code>FinderRev</code> was doing backward. The prefilter uses byte frequency heuristics to find candidate positions, but on repetitive structured data like JSON it generates tons of false positives and keeps hitting the slow path.</p> <p><strong>memmem::Finder with prefilter disabled, 9.2 seconds</strong></p> <p>I thought the prefilter must be the problem. Disabled it via <code>FinderBuilder::new().prefilter(Prefilter::None)</code>. Same speed. Also lost cancellation support because <code>find()</code> just blocks on the entire data slice until its done. No progress bar, no cancel button. Great.</p> <p><strong>Rarest byte memchr, 6.3 seconds</strong></p> <p>Went back to the memchr approach but smarter this time. Wrote a byte frequency table tuned for JSON (structural chars like <code>&quot;</code> <code>:</code> <code>,</code> scored high, rare letters scored low) and picked the least common byte in the query as anchor. This actually beat memmem::Finder, which surprised me. But still 3x slower than backward.</p> <p><strong>Two byte pair anchor, 6.2 seconds</strong></p> <p>Instead of anchoring on one rare byte, pick the rarest two consecutive bytes from the needle. Use memchr on the first one, immediately check if the next byte matches before doing the full comparison. Barely any improvement. The problem wasnt the verification cost, it was that memchr itself was stopping about 2 million times at the anchor byte.</p> <p><strong>Why is FinderRev so fast?</strong></p> <p>After some digging, turns out <code>FinderRev</code> deliberately does not use the SIMD prefilter, <del>to keep binary size down</del> <em>&quot;because it wasn&#39;t clear it was worth the extra code&quot;</em>. On structured data full of repetitive delimiters, the &quot;dumber&quot; algorithm just plows straight through without the overhead. The thing that was supposed to make forward search faster was actually making it slower on this kind of data.</p> <p><strong>FinderRev powered forward search, 1.8 seconds</strong></p> <p>At this point it was still annoying me. So I thought, if reverse is fast and forward is slow, why not just use reverse for forward? I process the file in 5MB chunks from the beginning to the end. For each chunk I call <code>rfind()</code> as a quick existence check, is there any match in this chunk at all? If no, skip it, move to the next one. That rejection happens at about 533 MB/s. When rfind returns a hit, I know there is a match somewhere in that 5MB chunk, so I do a small <code>memmem::find()</code> on just that chunk to locate the first occurrence.</p> <p>In practice 99.9% of chunks have no match and get skipped at FinderRev speed. The one chunk that actually contains the result takes about 0.03 seconds for the forward scan. Total: 1.8 seconds for the entire 1GB file.</p> <p>All benchmarks on Samsung Galaxy S23 Ultra, ARM64, 1GB JSON with about 50 million lines, case sensitive forward search for a unique 24 byte string.</p> <p>Since last time the app also picked up a full API Client (Postman collection import, OAuth 2.0, AWS Sig V4), a HAR network analyzer, highlight keywords with color picker and pinch to zoom. Still one person, still Rust powered, still occasionally surprised when things actually work on a phone.</p> <p>Web: <a href="https://giantjson.com/">giantjson.com</a></p> <p><strong>Has anyone else hit this Finder vs FinderRev gap on non natural language data?</strong><br/> <strong>Curious if this is a known thing or if I just got lucky with my data pattern.</strong></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/kotysoft"> /u/kotysoft </a> <br/> <span><a href="https://i.redd.it/12f4mxbrr7mg1.png">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/rust/comments/1rgzhhl/searching_1gb_json_on_a_phone_44s_to_18s_a/">[comments]</a></span></div>
          </li>
  
        </ul>
  
        <h3 class="subreddit">r/gamedev</h3>
        <ul class="item-list">
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhlfsv/how_common_is_it_for_solos_and_indies_to_reuse/" target="_blank">How common is it for solos and indies to reuse their same sprites or models between games</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I&#39;m starting to accrue quite a backlog of sprites and all kinds of Art stuff. Is reusing your own stuff common game to game? Even if you switch genres completely? Is it the kind of thing anybody cares about </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/JobCentuouro"> /u/JobCentuouro </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhlfsv/how_common_is_it_for_solos_and_indies_to_reuse/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhlfsv/how_common_is_it_for_solos_and_indies_to_reuse/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhkmh5/3_months_after_releasing_my_indie_simulator_on/" target="_blank">3 months after releasing my indie simulator on Steam: only 5 reviews ‚Äî here‚Äôs what I think happened</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I released my indie game <em>Konbini Simulator</em> in December 2025.</p> <p>It‚Äôs been a few months, and the game currently has 5 Steam reviews.</p> <p>I wanted to share some honest reflections and get input from other devs.</p> <p><strong>Context:</strong></p> <ul> <li>Solo development</li> <li>Small budget (basically $0 marketing)</li> <li>Simulator genre (retail/store management)</li> <li>No publisher</li> <li>Limited influencer coverage</li> </ul> <p><strong>Observations:</strong></p> <ul> <li>Initial visibility spike from launch was short-lived</li> <li>Wishlist conversion was lower than expected</li> <li>Trailer quality may not have communicated the hook clearly</li> <li>Steam algorithm did not seem to push the game further after launch</li> </ul> <p><strong>What I‚Äôm trying to understand:</strong></p> <ul> <li>At what point does Steam momentum realistically die?</li> <li>How much does trailer quality affect first-week performance?</li> <li>Is the simulator market now too saturated?</li> <li>What should be prioritized post-launch: updates, discounts, or external marketing?</li> </ul> <p>Would really appreciate any constructive insights from devs who‚Äôve gone through similar launches.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Mobaroid"> /u/Mobaroid </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhkmh5/3_months_after_releasing_my_indie_simulator_on/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhkmh5/3_months_after_releasing_my_indie_simulator_on/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhjgeh/looking_for_advice/" target="_blank">Looking for advice</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>How do you balance the expectation you got in your first game, like I definitely want it working properly, gotta give it the best narrative I came up with, I designed my characters from scratch and I&#39;d like a proper 3d model I want to make myself which will probably take a while, and I think all of this makes me too lazy to even pick up on what I worked on previously, help my project is collecting dust. I have been working on it since probably last October. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/vvoilet"> /u/vvoilet </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhjgeh/looking_for_advice/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhjgeh/looking_for_advice/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhiewh/how_can_you_handle_things_that_require_subtick/" target="_blank">How can you handle things that require sub-tick precission?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Hi, I&#39;m working on a weapon system, I&#39;m finding it hard to make the animations/shots look nice since the shots don&#39;t trigger on the same tick as the physcis tick which results in variable shot time. What are some ways to handle this? Checking every render frame doesn&#39;t sound right to me. Is it just visual decoupling? Just loop teh animation but handle the shots per physcis tick? if so you&#39;d need to keep track of timings and interpolate previous and current positions by the delta to check for hits?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/moshujsg"> /u/moshujsg </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhiewh/how_can_you_handle_things_that_require_subtick/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhiewh/how_can_you_handle_things_that_require_subtick/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhhrmv/i_made_a_practical_comparison_to_see_if/" target="_blank">I made a practical comparison to see if video-based mocap solutions are actually viable for anything</a>
            <div class="item-content"><table> <tr><td> <a href="https://www.reddit.com/r/gamedev/comments/1rhhrmv/i_made_a_practical_comparison_to_see_if/">  </a> </td><td> <!-- SC_OFF --><div class="md"><p>To make it as objective as possible, both animations are exported completely raw, without any cleanup. Hopefully, this gives you some solid insight into whether it&#39;s worth investing thousands in hardware right now, or if a camera on a tripod is enough for your current project&#39;s needs.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Dapper_Astronaut_603"> /u/Dapper_Astronaut_603 </a> <br/> <span><a href="https://www.youtube.com/watch?v=q4ZqIz141pI">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhhrmv/i_made_a_practical_comparison_to_see_if/">[comments]</a></span> </td></tr></table></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhg7e1/solo_developing_a_3d_action_rpg_as_a_nonartist/" target="_blank">Solo developing a 3D action RPG as a non-artist</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p><strong>Context:</strong></p> <p>I would like to share my experience developing my first ever self-made game on Steam, Remi: <a href="https://store.steampowered.com/app/4083200/Remi/">https://store.steampowered.com/app/4083200/Remi/</a> . It is an anime style action RPG that I worked on side while working as a software developer. This post is not necessarily meant to be generalized advice, but moreso my experience working on the game as a solo developer</p> <p><strong>Making a game as a solo developer is hard:</strong></p> <p>In order to make a 3d game, you have to worry about gameplay stems, 3d character models, textures, rigging, animations, 3d environments, VFX, UI, sound effects, input, and performance to some extent. But most of all, the hardest part of solo game development is motivation. On most days, when I finish work as a software developer, I generally don&#39;t want to spend more time doing technical work. </p> <p>How you fix this is up to you, but a big motivator for me is regularly creating milestones, TODO lists, and expected deadlines for myself so when I am in the mood for working, I know exactly what to work on. At the start, these milestones are often times rough prototypes that are made quickly to test out an idea. Which leads me to my next point...</p> <p><strong>It doesn&#39;t have to be perfect:</strong></p> <p>Time is a resource, and every minute you spend working on a part of your game could be spent working on something else. I often time find myself creating systems that don&#39;t necessarily optimize fidelity, scalability or performance, or anything like that - I optimize for dev time, hackathon style.</p> <p>For the visuals, my cope is that if something is too good, then all that will do is raise expectations, which is not necessarily a good thing. If my environment is beautiful in one level, then the expectation will be that it will be as polished in another. I don&#39;t have time (or sometimes even the interest) to make everything look good, so it&#39;s okay to settle for lower visual fidelity throughout the game.</p> <p>This is often true for code as well, despite being contrary to everything they teach you in programming. As a solo developer especially, often times big systems incur a lot of tech debt if ideas change. And if it doesn&#39;t, it&#39;s probably too generic to be useful without more work anyway. I&#39;ve spent so much time refactoring systems to just abandon it later because either I want to try out a new idea or I learned a new way to do things.</p> <p><strong>It&#39;s important to impose limitations:</strong></p> <p>The current codebase of Remi is only one year old. Although the idea has been in my head for around 5 years. And that is because I completely scrapped and restarted the codebase 5 times. It went from: Slow-paced souls-like game &gt; Vampire survivors-like game &gt; 2D perspective metroidvania game &gt; Top-down action roguelike &gt; Faster paced action RPG game. The reason for the pivots is often due to feature creep, trend chasing, or I just get inspired from whatever games I&#39;m currently playing.</p> <p>When I finally decided to define an ultimatum is when I started seeing the light at the end of the tunnel. Originally I planned 8 boss enemies. I restricted the number of boss enemies to 3, and normal enemies to 6. The player character has a basic attack, two abilities, and an ultimate ability. Once I had these rules set in place is when I finally got time for UI, difficulty balancing, controller support, music, sound, and putting everything else together.</p> <p><strong>Other Lingering thoughts:</strong></p> <ul> <li>A lot of people are not PC gamers</li> <li>Difficult games are not everyone&#39;s cup of tea, especially for super small indie games such as this one - Most people that I&#39;ve seen could not beat the first boss. Ironically, while playtesting, I was afraid the game would be too easy and they&#39;ll finish the game too quickly</li> <li>Making a low effort demo for a 1-3 hour game is probably redundant</li> <li>The Steam review process is pretty slow and you should expect to have your game almost completely finished at least 3 weeks before it is released</li> <li>I did zero advertising for my game besides just word of mouth among my friends. Surprisingly, it got 1000+ page visits and 100+ wishlists before releasing. Unfortunately, the number of actual purchases was only a small fraction of the wishlists. This is okay though, as I never expected to make a profit from it.</li> <li>The Steam Curator Connect program is probably not worth participating in</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/DevichiX"> /u/DevichiX </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhg7e1/solo_developing_a_3d_action_rpg_as_a_nonartist/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhg7e1/solo_developing_a_3d_action_rpg_as_a_nonartist/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhduoh/is_it_worth_creating_all_my_own_assets_or_is_that/" target="_blank">Is it worth creating all my own assets or is that absurdly wasteful?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>As a pixel artist, it&#39;s rather difficult to source assets, it&#39;s not like we have tons of free open source poly stuff that we can use like polyhaven. So it becomes rather difficult to find exactly what you&#39;re looking for and that&#39;s why in my 2D pixel art game, I was creating all my assets myself, the trees, the houses, etc... </p> <p>Now I&#39;m starting to learn 3D development... It looks like there is a lot of really good free poly assets, like tree bark, tree leaves, flowers stuff like that. But I don&#39;t know if it&#39;s worth using these or if I should instead be creating everything myself? Every flower, every tree, every rock, everything?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/buttflapper444"> /u/buttflapper444 </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhduoh/is_it_worth_creating_all_my_own_assets_or_is_that/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhduoh/is_it_worth_creating_all_my_own_assets_or_is_that/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhdsjw/your_small_game_probably_is_not_small_enough/" target="_blank">Your small game probably is not small enough</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>I think everyone has heard the advice to make the first game very small</p> <p>It wasn&#39;t clear to me what that actually means. Sometimes people give a specific recommendation, like make a game in 3‚Äì6 months. To me that sounded like extremely short development cycle and very simple project without any chance of being interesting to players</p> <p>But now I actually think it‚Äôs the right approach. And even if you plan a game for 6 months, there‚Äôs a high chance it will end up taking a full year or more</p> <p>I think it&#39;s important to understand that scope isn‚Äôt just about the amount of content or the genre. It‚Äôs also about quality. A game can be mechanically simple, but if you aim for good art or high level of polish in general, that can dramatically extend development time.</p> <p>I‚Äôm making a game inspired by Hotline Miami, which I thought was quite simple project. And it kinda is. However last year I‚Äôve put around 1k hours into it, and I still don‚Äôt really have a ‚Äúgame.‚Äù I have a somewhat polished controller, couple of test levels, a DMC-like style system, and art for three biomes. That‚Äôs it. There‚Äôs no menu, no settings, no localization, no gamepad support, no narrative of any sort, no content, no music. Game is basically in a state of advanced prototype, I guess I can call it a vertical slice </p> <p>Of course, it might be due to how I personally approach development, how I iterate on things too much, etc., but still, as a matter of fact, after 1k hours I‚Äôm only halfway through development</p> <p>So...Even if you picked relatively small scope, think more about how you can reduce it even further</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/hogon2099"> /u/hogon2099 </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhdsjw/your_small_game_probably_is_not_small_enough/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhdsjw/your_small_game_probably_is_not_small_enough/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhctvi/where_do_you_design_your_games/" target="_blank">where do you "design" your games?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>all my &quot;game concepts&quot; are just text files in a few folders, but i guess its not the optimal way, so what do you use to set lore, systems, ideas and the rest of the &quot;manifesto&quot;?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Coso_Che_Cosa"> /u/Coso_Che_Cosa </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rhctvi/where_do_you_design_your_games/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhctvi/where_do_you_design_your_games/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rhcpe8/how_to_get_a_rigid_looking_tiles_movement_on_a/" target="_blank">How to get a rigid looking tiles movement on a sphere</a>
            <div class="item-content"><table> <tr><td> <a href="https://www.reddit.com/r/gamedev/comments/1rhcpe8/how_to_get_a_rigid_looking_tiles_movement_on_a/">  </a> </td><td> <!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I‚Äôm building a force-driven planetary sim on an icosphere. I‚Äôve moved from random noise to a physics model, but I‚Äôm stuck on one thing: my plates move like liquid.</p> <p>I calculate forces like Slab Pull and Ridge Push to get a Net Torque for each plate. However, when I apply the movement, the continents stretch and warp into a &quot;soup&quot; instead of moving as solid blocks.</p> <p>I recently switched to Rodrigues&#39; Rotation Formula to rotate tile vectors directly around an Euler Pole (Rotation Axis).<br/> But even with the right math, the &quot;binding&quot; between tiles feels fluid. If I move tiles independently, the plate disintegrates. If I move them as a group, I struggle with how to handle the fixed grid.</p> <p>How do you &quot;lock&quot; tiles into a rigid plate so they rotate as one unit without stretching?<br/> Should I be moving the actual mesh vertices (Lagrangian) or just &quot;sliding&quot; the data (Crust Thickness, etc.) between fixed tiles (Advection)?<br/> How do you handle deformation (Orogeny/Rifting) only at the edges while keeping the &quot;core&quot; of the plate 100% rigid?</p> <p>I‚Äôd love to hear from anyone who has tackled Rigid Body Dynamics on a sphere. Any specific algorithms or &quot;lessons learned&quot; would be huge!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Magistairs"> /u/Magistairs </a> <br/> <span><a href="https://youtube.com/watch?v=IZgrhLIyU0k&amp;si=eX--b-51DosBsBel">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rhcpe8/how_to_get_a_rigid_looking_tiles_movement_on_a/">[comments]</a></span> </td></tr></table></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rh85tg/next_fest_takeaway_gamers_love_critters/" target="_blank">Next Fest takeaway: gamers love critters?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Scrolling through Next Fest right now, I think my takeaway is that games prominently featuring cats or frogs tend to outperform. I think ducks may be in 3rd place, but I‚Äôm not keeping a careful count.</p> <p>:)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PersonOfInterest007"> /u/PersonOfInterest007 </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rh85tg/next_fest_takeaway_gamers_love_critters/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rh85tg/next_fest_takeaway_gamers_love_critters/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rgzusy/can_a_game_recover_from_a_failed_launch/" target="_blank">Can a game recover from a failed launch?</a>
            <div class="item-content"><!-- SC_OFF --><div class="md"><p>Basically the title‚Ä¶</p> <p>Is there anything like an ‚Äúopen window‚Äù on Steam? </p> <p>I read something about the first two weeks after launch mattering most, as the algorithm decides whether to push the game or not. But let‚Äôs assume you launch a game with a low number of wishlists and it only generates a few sales in the first two weeks.</p> <p>Is it possible to recover and get recommended again sometime in the future if, let‚Äôs say, you manage to drive traffic and sell lots of copies in a short time period, a few months after launch, or is the game basically dead if the launch fails?‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/BlobKingGame"> /u/BlobKingGame </a> <br/> <span><a href="https://www.reddit.com/r/gamedev/comments/1rgzusy/can_a_game_recover_from_a_failed_launch/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rgzusy/can_a_game_recover_from_a_failed_launch/">[comments]</a></span></div>
          </li>
  
          <li>
            <a href="https://www.reddit.com/r/gamedev/comments/1rgy3u6/asset_hoard_v015_fonts_unity_packages_and/" target="_blank">Asset Hoard v0.1.5 -- Fonts, Unity packages, and navigation history</a>
            <div class="item-content"><table> <tr><td> <a href="https://www.reddit.com/r/gamedev/comments/1rgy3u6/asset_hoard_v015_fonts_unity_packages_and/">  </a> </td><td> <!-- SC_OFF --><div class="md"><p><strong>Asset Hoard v0.1.5 -- Fonts, Unity packages, and navigation history</strong></p> <p>Hey everyone! v0.1.5 just dropped. Here&#39;s what&#39;s new:</p> <p>‚ú® <strong>New file types</strong></p> <ul> <li>Font files (<code>.ttf</code>, <code>.otf</code>, <code>.woff</code> and more) now have thumbnails and previews</li> <li>Improved <code>.unitypackage</code> support with thumbnail extraction and per-bundle version tracking</li> </ul> <p>üöÄ <strong>Features</strong></p> <ul> <li><strong>Move to Bundle picker</strong> -- fuzzy-searchable bundle tree right from the context menu, so you can reorganise without losing your place</li> <li><strong>Back/forward navigation</strong> -- browse your history with <code>Alt+Left</code> / <code>Alt+Right</code> or mouse side buttons</li> <li><strong>Bundle cover cropping</strong> -- pick and crop your own cover images for bundles</li> <li><strong>Remove orphaned assets</strong> -- audit your library for broken file links and clean them up in one click</li> <li><strong>Unity package directories</strong> now have their own dedicated settings panel</li> </ul> <p>üìÇ <strong>Watched folders</strong></p> <ul> <li>Pause and resume individual folder watchers</li> <li>Cleaner, less noisy notifications</li> <li>Better progress tracking during file events</li> </ul> <p>üêõ <strong>Bug fixes</strong></p> <ul> <li>Undo/redo counts now correctly update bundle cumulative counts</li> <li>Improved SVG and plain text metadata handling</li> <li>&quot;New&quot; badges can now be cleared after watched folder imports</li> <li>Better error handling when thumbnail generation fails</li> </ul> <p>Still in closed beta -- if you want in, drop a comment or join the Discord. Happy hoarding! üè∞</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/dolfoz"> /u/dolfoz </a> <br/> <span><a href="https://assethoard.com/releases/0.1.5">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/gamedev/comments/1rgy3u6/asset_hoard_v015_fonts_unity_packages_and/">[comments]</a></span> </td></tr></table></div>
          </li>
  
        </ul>
  
      </div>
  
    </div>
  </body>
  </html>